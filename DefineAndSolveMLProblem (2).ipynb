{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Double click this Markdown cell to make it editable, and record your answers here.>\n",
    "\n",
    "Data Set Chosen\n",
    "Data Set: bookReviewsData.csv\n",
    "\n",
    "Prediction Task\n",
    "Prediction Objective: Predict the rating of book reviews.\n",
    "\n",
    "Label: Rating (e.g., 1 to 5 stars)\n",
    "\n",
    "Learning Type and Problem Classification\n",
    "Supervised/Unsupervised: Supervised\n",
    "\n",
    "Type of Problem: Classification, specifically multi-class classification (ratings from 1 to 5 stars)\n",
    "\n",
    "Features\n",
    "Features:\n",
    "\n",
    "Review text\n",
    "Review length\n",
    "Author information\n",
    "Review date\n",
    "Book genre\n",
    "\n",
    "Importance of the Problem\n",
    "Importance: Predicting the rating of book reviews helps publishers and authors understand how well a book is being received by the audience. It can inform marketing strategies, editorial decisions, and improve future book offerings. For example, if the model predicts lower ratings for certain genres or authors, a company can investigate further to understand the underlying causes and make necessary improvements to meet reader expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File path for the book reviews data set\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "# Load the data set\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data? \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Double click this Markdown cell to make it editable, and record your answers here.>\n",
    "\n",
    "New Feature List\n",
    "After inspecting the data, I have decided to focus on the following features:\n",
    "\n",
    "Features to Keep:\n",
    "\n",
    "review_text: The text of the book review.\n",
    "review_length: The length of the review text.\n",
    "author: Information about the author, encoded appropriately if necessary.\n",
    "Features to Remove:\n",
    "\n",
    "Any features that are irrelevant to the prediction task or contain too many missing values that can't be reasonably filled.\n",
    "Data Preparation Techniques\n",
    "To prepare the data for modeling, I will apply the following data preparation techniques:\n",
    "\n",
    "Handling Missing Values:\n",
    "\n",
    "For numerical columns, fill missing values with the mean of the column.\n",
    "For categorical columns, fill missing values with the mode or a placeholder value like 'Unknown'.\n",
    "Feature Engineering:\n",
    "\n",
    "Text Data: Convert the review_text feature into numerical features using TF-IDF (Term Frequency-Inverse Document Frequency) vectorization.\n",
    "Review Length: Create a new feature review_length by calculating the length of each review.\n",
    "Author Information: Apply one-hot encoding if necessary to convert categorical author data into numerical form.\n",
    "Outlier Detection and Removal:\n",
    "\n",
    "Use box plots to detect outliers in numerical features and apply appropriate techniques to handle them, such as capping or removing outliers.\n",
    "Scaling Features:\n",
    "\n",
    "Apply standard scaling to numerical features to ensure they are on a comparable scale, which is essential for many machine learning algorithms.\n",
    "Addressing Class Imbalance:\n",
    "\n",
    "Use techniques such as class weighting during model training to address any class imbalance in the target variable.\n",
    "Model Selection\n",
    "The primary model to be used is Logistic Regression, due to its simplicity and interpretability for binary classification problems. Other models may also be considered for comparison and improvement purposes:\n",
    "\n",
    "Logistic Regression: As a baseline model.\n",
    "Support Vector Machines (SVM): For potentially better performance on high-dimensional data.\n",
    "Random Forest: For robustness and ability to handle feature interactions.\n",
    "Neural Networks: For potentially capturing more complex patterns in the data.\n",
    "Model Training and Evaluation Plan\n",
    "Model Training:\n",
    "\n",
    "Split the data into training and testing sets (e.g., 75% training, 25% testing).\n",
    "Train the Logistic Regression model using the training set, applying techniques such as class weighting to handle any imbalance in the target variable.\n",
    "Train additional models for comparison if needed.\n",
    "Performance Analysis:\n",
    "\n",
    "Evaluate the model's performance using metrics such as accuracy, precision, recall, and F1 score.\n",
    "Use cross-validation to ensure the model generalizes well to new data and is not overfitting to the training data.\n",
    "Model Improvement:\n",
    "\n",
    "Analyze model performance metrics and identify areas for improvement.\n",
    "Tune hyperparameters using techniques such as grid search or random search.\n",
    "Experiment with feature selection and engineering to identify the most predictive features.\n",
    "Consider ensemble methods (e.g., bagging, boosting) to combine multiple models and improve performance.\n",
    "Final Model Selection and Validation:\n",
    "\n",
    "Select the best-performing model based on validation metrics.\n",
    "Perform a final evaluation on the test set to confirm the model's performance.\n",
    "Document and interpret the final model's predictions and their implications for understanding book review sentiments.\n",
    "Timeline\n",
    "Week 1: Data exploration and cleaning, feature engineering, initial model training.\n",
    "Week 2: Model evaluation, hyperparameter tuning, model comparison.\n",
    "Week 3: Final model selection, validation, and documentation.\n",
    "By following this plan, I aim to build a robust and accurate model to predict the sentiment of book reviews, providing valuable insights for publishers and authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 13:54:28.654239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-26 13:54:28.654274: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Neural network packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Additional utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# File path for the book reviews data set\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "# Load the data set\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n",
    "\n",
    "# Importing necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Neural network packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Additional utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
